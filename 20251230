Ollama로 나만의 LLM 구축하기
📌 목표

로컬 환경에서 실행되는 개인 전용 LLM 구축

인터넷 없이도 동작

특정 역할(개발 조언, 프로젝트 리뷰, 멘탈 코치 등)에 최적화

추후 웹 서비스/챗봇으로 확장 가능하게 설계

1️⃣ Ollama를 선택한 이유

기존 OpenAI API 기반 LLM의 한계:

💸 토큰 비용

🌐 네트워크 의존

🔒 프롬프트/데이터 외부 전송

Ollama의 장점

로컬 실행 (완전 오프라인 가능)

모델 관리 간단

커스텀 모델 생성 지원

M1/M2 + 일반 PC에서도 충분히 실험 가능

👉 결론: “개인용 LLM 실험 플랫폼”으로 최적

2️⃣ 개발 환경

OS: Windows / macOS

CPU 기반 (GPU 없어도 가능)

Ollama

Base Model:

llama3

mistral

phi

(처음엔 llama3 추천)

3️⃣ Ollama 설치
# macOS
brew install ollama

# Windows
공식 사이트에서 설치


서버 실행:

ollama serve


모델 다운로드:

ollama pull llama3


실행 확인:

ollama run llama3


👉 여기까지 되면 기본 LLM은 이미 성공

4️⃣ “나만의 LLM”의 핵심 개념

중요한 사실 하나 짚고 가자 👇
👉 Ollama로 만드는 개인 LLM = 파인튜닝 ❌ / 프롬프트 + 설정 조합 ⭕

즉,

모델 새로 학습 ❌

행동 규칙, 말투, 역할을 고정한 LLM 생성 ⭕

5️⃣ Modelfile로 커스텀 LLM 만들기
📄 Modelfile 생성
FROM llama3

SYSTEM """
너는 개발자 전용 AI 비서다.
- 반말로 말한다
- 결론부터 말한다
- 쓸데없는 설명 안 한다
- 현실적인 조언만 한다
- 개발자 멘탈 관리도 같이 해준다
"""


모델 생성:

ollama create my-dev-llm -f Modelfile


실행:

ollama run my-dev-llm


👉 이 순간부터 말투 + 사고방식 고정된 나만의 LLM 완성

6️⃣ 성능 튜닝 (은근히 중요한 부분)

Modelfile에서 추가 가능 👇

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER repeat_penalty 1.1


temperature ↓ → 현실적, 차분

temperature ↑ → 아이디어 폭발

repeat_penalty ↑ → 말 반복 줄이기

👉 여기서 LLM 성격이 갈린다

7️⃣ 데이터 넣고 싶을 때 (실전용)
방법 1️⃣ 프롬프트 주입 (가장 현실적)

개발 일지

내 프로젝트 설명

나의 사고방식 문서

→ 질문할 때 같이 넣음

방법 2️⃣ RAG 구조 (중급)

내 노션/마크다운 문서

벡터DB

검색 → LLM 답변

👉 “기억하는 LLM” 느낌 구현 가능

8️⃣ 내가 느낀 한계와 현실

❌ 진짜 파인튜닝은 어려움
❌ 최신 GPT급 추론력은 아님
⭕ 대신 내 스타일 고정 + 빠른 응답은 압승
⭕ 개인 프로젝트 / 멘탈 코치 / 개발 조언용으로 충분

9️⃣ 확장 계획

Next.js + API 연동

웹 기반 개인 챗봇

프로젝트 리뷰 전용 LLM

개발 일지 자동 피드백 봇

👉 최종 목표:
“나보다 나를 잘 아는 로컬 AI 비서”

🔥 한 줄 정리 (개발 일지용)

Ollama를 활용해 로컬 환경에서 동작하는 개인 전용 LLM을 구축했다.
모델을 새로 학습시키는 방식이 아닌, 시스템 프롬프트와 파라미터 튜닝을 통해
말투·사고방식·역할이 고정된 AI를 만드는 데 집중했다.
